<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Splatter-360: Generalizable 360$^{\circ}$ Gaussian Splatting for Wide-baseline Panoramic Images.">
  <meta name="keywords" content="Gaussian Splatting">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Splatter-360: Generalizable 360$^{\circ}$ Gaussian Splatting for Wide-baseline Panoramic Images</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  </script>
  <script type="text/javascript"
    src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
</head>

<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hd-fusion.github.io">
            HDFusion
          </a>
          <a class="navbar-item" href="https://3dgir.github.io">
            GIR
          </a>
          <a class="navbar-item" href="https://3d-aigc.github.io/GEA">
            GEA
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>
<!-- Zheng Chen, Chenming Wu, Zhelun Shen, Chen Zhao, Weicai Ye, Haocheng Feng, Errui Ding, Song-Hai Zhang -->

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">Splatter-360: Generalizable 360 Gaussian Splatting for Wide-baseline Panoramic Images</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=fmbBnegAAAAJ">Zheng Chen</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://chenming-wu.github.io/">Chenming Wu</a><sup>2*</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=pfzhh0IAAAAJ">Zhelun Shen</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://openreview.net/profile?id=~Chen_Zhao9">Chen Zhao</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://ywcmaike.github.io/">Weicai Ye</a><sup>3</sup>,</span> <br>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=pnuQ5UsAAAAJ">Haocheng Feng</a><sup>2</sup>,</span>
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=1wzEtxcAAAAJ&hl=en">Errui Ding</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=AWtV-EQAAAAJ">Song-Hai Zhang</a><sup>1†</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <sup>1</sup><span class="author-block">Tsinghua University, </span>  
            <sup>2</sup><span class="author-block">Baidu VIS, </span> 
            <sup>3</sup><span class="author-block">Zhejiang University</span>
            <br> <FONT color=#8B0000><b>Accepted to CVPR 2025</b></FONT>
          </div>
          <div class="is-size-6 publication-authors">
            <sup>*</sup><span class="author-block">Equal contribution</span>
            <sup>†</sup><span class="author-block">Corresponding author</span>
            
          </div>


          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2412.06250"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=" "
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/thucz/splatter360"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <!-- <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/teaser.png" 
               class="interpolation-image" 
               alt="Interpolate start reference image" 
               style="width: 100%; height: auto; display: block; margin: 0 auto;"> <br>
          <p class="imgae-description has-text-centered"> Our proposed TexGaussian is capable of generating high-quality PBR material given the input 3D mesh based on the corresponding textual descriptions. The generated results are naturally compatible with modern graphical engines for photo-realistic rendering under different environment maps.</p>
    </div>
  </div>
</section> -->



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- Physically Based Rendering (PBR) materials play a crucial role in modern graphics, enabling photorealistic rendering across diverse environment maps. Developing an effective and efficient algorithm that is capable of automatically generating high-quality PBR materials rather than RGB texture for 3D meshes can significantly streamline the 3D content creation. Most existing methods leverage pre-trained 2D diffusion models for multi-view image synthesis, which often leads to severe inconsistency between the generated textures and input 3D meshes. This paper presents TexGaussian, a novel method that uses octant-aligned 3D Gaussian Splatting for rapid PBR material generation. Specifically, we place each 3D Gaussian on the finest leaf node of the octree built from the input 3D mesh to render the multiview images not only for the albedo map but also for roughness and metallic. Moreover, our model is trained in a regression manner instead of diffusion denoising, capable of generating the PBR material for a 3D mesh in a single feed-forward process. Extensive experiments on publicly available benchmarks demonstrate that our method synthesizes more visually pleasing PBR materials and runs faster than previous methods in both unconditional and text-conditional scenarios, which exhibit better consistency with the given geometry. -->
          Wide-baseline panoramic images are frequently used in
          applications like VR and simulations to minimize capturing labor costs and storage needs. However, synthesizing
          novel views from these panoramic images in real time remains a significant challenge, especially due to panoramic
          imagery's high resolution and inherent distortions. Although existing 3D Gaussian splatting (3DGS) methods can
          produce photo-realistic views under narrow baselines, they
          often overfit the training views when dealing with widebaseline panoramic images due to the difficulty in learning precise geometry from sparse 360◦ views. This paper presents Splatter-360, a novel end-to-end generalizable 3DGS framework designed to handle wide-baseline
          panoramic images. Unlike previous approaches, Splatter-
          360 performs multi-view matching directly in the spherical
          domain by constructing a spherical cost volume through a
          spherical sweep algorithm, enhancing the network's depth
          perception and geometry estimation. Additionally, we introduce a 3D-aware bi-projection encoder to mitigate the distortions inherent in panoramic images and integrate crossview attention to improve feature interactions across multiple viewpoints. This enables robust 3D-aware feature representations and real-time rendering capabilities. Experimental results on the HM3D [27] and Replica [32] demonstrate that Splatter-360 significantly outperforms state-ofthe-art NeRF and 3DGS methods (e.g., PanoGRF, MVSplat,
          DepthSplat, and HiSplat) in both synthesis quality and generalization performance for wide-baseline panoramic images.          
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <!-- <h2 class="title is-3">Video</h2> -->
        <!-- <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div> -->
        
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method</h2>
        <!-- Interpolating. -->
          <div class="content has-text-justified">
          <img src="./static/images/fig_pipeline.jpg" 
               class="interpolation-image" 
               alt="Interpolate start reference image" 
               style="width: 100%; height: auto; display: block; margin: 0 auto;"> <br>
          <p class="image-description has-text-centered">Our Splatter-360 processes 360° panoramic images using a bi-projection encoder that extracts features from both equirectangular
            projection (ERP) and cube-map projection (CP) through multi-view transformers. These features are used for spherical cost volume
            construction, and multi-view matching is performed between the reference and source views in spherical space. Next, a refinement U-Net
            is applied to enhance the spherical cost volume, yielding refined cost volumes and more accurate spherical depth estimations. These refined
            outputs are then fed into the Gaussian decoder, which produces pixel-aligned Gaussian primitives for synthesizing novel views.</p>
<br><br>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Video
      </h2>
     <video id="video" autoplay muted loop playsinline style="height: 80%;">
        <source src="./static/videos/video.mp4"
                type="video/mp4">
      </video>
      <p class="video-description has-text-centered">Novel view rendering with wide-baseline inputs on HM3D and Replica.</p>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">More results
      </h2>
      <img src="./static/images/hm3d_cmp.jpg" 
               class="interpolation-image" 
               alt="Interpolate start reference image" 
               style="width: 100%; height: auto; display: block; margin: 0 auto;">
          <p class="image-description has-text-centered">Novel view synthesis results on HM3D with wide-baseline inputs.</p> <br>
      <img src="./static/images/replica_cmp.jpg" 
        class="interpolation-image" 
        alt="Interpolate start reference image" 
        style="width: 100%; height: auto; display: block; margin: 0 auto;"> <br>
     <p class="image-description has-text-centered">Novel view synthesis results on Replica with wide-baseline inputs.</p>
     <img src="./static/images/depth_cmp_replica.jpg" 
        class="interpolation-image" 
        alt="Interpolate start reference image" 
      style="width: 100%; height: auto; display: block; margin: 0 auto;"><br>
      <p class="image-description has-text-centered"><b>Novel perspective view depth results on Replica with wide-baseline inputs.</p>
      <img src="./static/images/threeviews.jpg" 
        class="interpolation-image" 
        alt="Interpolate start reference image" 
      style="width: 50%; height: auto; display: block; margin: 0 auto;">
      <p class="image-description has-text-centered">Quantitative Results with three-view inputs.</p>

      <img src="./static/images/narrow_baseline.jpg" 
        class="interpolation-image" 
        alt="Interpolate start reference image" 
      style="width: 50%; height: auto; display: block; margin: 0 auto;">
      <p class="image-description has-text-centered">Quantitative Results with narrow-baseline inputs.</p>

    </div>
  </div>
</section>






      </div>
    </div>
    <!--/ Animation. -->
    <div class="columns is-centered">

      <!-- Visual Effects. -->
     
    <!--/ Matting. -->
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{panogrf,
      title={Splatter-360: Generalizable 360◦ Gaussian Splatting for Wide-baseline
        Panoramic Images}, 
      author={Zheng Chen and Chenming Wu and Zhelun Shen and Chen Zhao and Errui Ding and Song-Hai Zhang},
      year={2024},
      <!-- eprint={2406.02058}, -->
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          
          <p>
            This website borrows the template from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> and <a href="https://hypernerf.github.io/">HyperNeRF</a>.
          </p>
        </div>
      </div>
      <a href="https://mapmyvisitors.com/web/1bw4d"  title="Visit tracker"><img src="https://mapmyvisitors.com/map.png?d=V1QdKPCWxEKaqBChctRV5hdvmreU-vbh4a-rO_5Occc&cl=ffffff" /></a>
    </div>
    
  </div>
</footer>

</body>
</html>
