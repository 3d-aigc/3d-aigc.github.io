<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="OpenGaussian: Towards Point-Level 3D Gaussian-based Open Vocabulary Understanding.">
  <meta name="keywords" content="Gaussian Splatting, Open Vocabulary, 3D Scene Understanding">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>OpenGaussian: Towards Point-Level 3D Gaussian-based Open Vocabulary Understanding</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  </script>
  <script type="text/javascript"
    src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
</head>

<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hd-fusion.github.io">
            HDFusion
          </a>
          <a class="navbar-item" href="https://3dgir.github.io">
            GIR
          </a>
          <a class="navbar-item" href="https://3d-aigc.github.io/GEA">
            GEA
          </a>
          <!-- <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a> -->
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">OpenGaussian: Towards Point-Level 3D Gaussian-based Open Vocabulary Understanding</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://yanmin-wu.github.io/">Yanmin Wu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href=" ">Jiarui Meng</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href=" ">Haijie Li</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://chenming-wu.github.io/">Chenming Wu</a><sup>2*</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=-VJZrUkAAAAJ&hl=en">Yahao Shi</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="https://cxh0519.github.io/">Xinhua Cheng</a><sup>1</sup>,</span> <br>
            <span class="author-block">
              <a href="https://openreview.net/profile?id=~Chen_Zhao9">Chen Zhao</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://openreview.net/profile?id=~Haocheng_Feng1">Haocheng Feng</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=1wzEtxcAAAAJ&hl=zh-CN">Errui Ding</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://jingdongwang2017.github.io/">Jingdong Wang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://jianzhang.tech/">Jian Zhang</a><sup>1*</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <sup>1</sup><span class="author-block">Peking University</span>, 
            <sup>2</sup><span class="author-block">Baidu VIS</span>, 
            <sup>3</sup><span class="author-block">Beihang University</span>
          </div>
          <div class="is-size-6 publication-authors">
            <sup>*</sup><span class="author-block">Corresponding authors</span>
          </div>


          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/ps/2406.02058"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2406.02058"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://3d-aigc.github.io/OpenGaussian"
                   class="external-link button is-normal is-rounded is-light">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming soon)</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <!-- <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- 
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          This paper introduces OpenGaussian, a method based on 3D Gaussian Splatting (3DGS) capable of 3D point-level open vocabulary understanding. Our primary motivation stems from observing that existing 3DGS-based open vocabulary methods mainly focus on 2D pixel-level parsing. These methods struggle with 3D point-level tasks due to weak feature expressiveness and inaccurate 2D-3D feature associations.
To ensure robust feature presentation and 3D point-level understanding, we first employ SAM masks without cross-frame associations to train instance features with 3D consistency. These features exhibit both intra-object consistency and inter-object distinction. Then, we propose a two-stage codebook to discretize these features from coarse to fine levels. At the coarse level, we consider the positional information of 3D points to achieve location-based clustering, which is then refined at the fine level.
Finally, we introduce an instance-level 3D-2D feature association method that links 3D points to 2D masks, which are further associated with 2D CLIP features. Extensive experiments, including open vocabulary-based 3D object selection, 3D point cloud understanding, click-based 3D object selection, and ablation studies, demonstrate the effectiveness of our proposed method.
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <!-- <h2 class="title is-3">Video</h2> -->
        <!-- <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div> -->
        
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method</h2>
        <!-- Interpolating. -->
          <div class="content has-text-justified">
          <img src="./static/images/pixel_3d_level.PNG" 
               class="interpolation-image" 
               alt="Interpolate start reference image" 
               style="width: 80%; height: auto; display: block; margin: 0 auto;">
          <p class="video-description has-text-centered">Two types of open-vocabulary understanding based on 3DGS.
            <b>(a) 2D pixel-level understanding</b>. The language-embedded 3D Gaussians are rendered into 2D feature maps, obtaining regions related to the query text as results. 
            <b>(b) 3D point-level understanding (ours)</b>, which selects Gaussians in 3D space related to the query text as results.</p>
          <img src="./static/images/framework.PNG" 
               class="interpolation-image" 
               alt="Interpolate start reference image" 
               style="width: 80%; height: auto; display: block; margin: 0 auto;">
          <p class="video-description has-text-centered"><b>Framework.</b> (a) We use the view-independent SAM boolean mask to train 3D instance features with 3D consistency for 3DGS. 
            (b) We propose a two-level codebook for discretizing instance features from coarse to fine. 
            (c) An instance-level 3D-2D feature association method to associate 2D CLIP features with 3D points without training.</p>
          <img src="./static/images/point_feat.PNG" 
               class="interpolation-image" 
               alt="Interpolate start reference image" 
               style="width: 80%; height: auto; display: block; margin: 0 auto;">
          <p class="video-description has-text-centered"><b>Visualization of 3D point features at different stages.</b> 
            (a) Reference image/mesh; (b) instance features learned from Sec. 3.1; 
            (c)-(d) Point features after discretization by coarse-level and fine-level codebook (Sec. 3.2).</p>
          <img src="./static/images/association.PNG" 
               class="interpolation-image" 
               alt="Interpolate start reference image" 
               style="width: 80%; height: auto; display: block; margin: 0 auto;">
          <p class="video-description has-text-centered"><b>3D point-2D CLIP feature association (Sec. 3.2).</b>
             We render 3D instance points to an arbitrary training view, and associate 3D points with 2D masks based on the principle of joint IoU and feature similarity, 
             which have already been extracted with mask-level CLIP features, thereby indirectly associating 3D points with CLIP features.</p>
<br><br>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Videos
      </h2>
      <video id="teaser1" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/point_feature_22M.mp4"
                type="video/mp4">
      </video>
      <p class="video-description has-text-centered">Instance <b>feature visualization</b> of 3D points.</p>
      <video id="teaser2" autoplay muted loop playsinline style="height: 60%;">
        <source src="./static/videos/scene_edit_6M.mp4"
                type="video/mp4">
      </video>
      <p class="video-description has-text-centered">Demonstration of <b>scene editing</b> capabilities. Based on the original scene reconstructed with OpenGaussian, 
        we can select objects for removal, insertion, or color modification.</p>
      <video id="teaser3" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/object_selection_11M.mp4"
                type="video/mp4">
      </video>
      <p class="video-description has-text-centered">Text/click-based <b>3D object Selection</b>.</p>
    </div>
  </div>
</section>

        <!-- <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div> -->
        <br/>
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <!-- <h3 class="title is-4">Re-rendering the input video</h3>
        <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/replay.mp4"
                    type="video/mp4">
          </video>
        </div> -->
        <!--/ Re-rendering. -->

      </div>
    </div>
    <!--/ Animation. -->
    <div class="columns is-centered">

      <!-- Visual Effects. -->
     
    <!--/ Matting. -->
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{wu2024opengaussian,
      title={OpenGaussian: Towards Point-Level 3D Gaussian-based Open Vocabulary Understanding}, 
      author={Yanmin Wu and Jiarui Meng and Haijie Li and Chenming Wu and Yahao Shi and Xinhua Cheng and Chen Zhao and Haocheng Feng and Errui Ding and Jingdong Wang and Jian Zhang},
      year={2024},
      eprint={2406.02058},
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          
          <p>
            This website borrows the template from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> and <a href="https://hypernerf.github.io/">HyperNeRF</a>.
          </p>
        </div>
      </div>
      <a href="https://mapmyvisitors.com/web/1bw4d"  title="Visit tracker"><img src="https://mapmyvisitors.com/map.png?d=V1QdKPCWxEKaqBChctRV5hdvmreU-vbh4a-rO_5Occc&cl=ffffff" /></a>
    </div>
    
  </div>
</footer>

</body>
</html>
